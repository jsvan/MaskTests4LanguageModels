{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsvan/MaskTests4LanguageModels/blob/main/Extension_of_Summerwinograndeattempt_to_more_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pmnlcR-R2MD"
      },
      "source": [
        "In this extension I will try out more models, first tuning generic language models on the debiased dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMvKLP9taL-G"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkyD6UlObpsl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "# You can switch between these two datasets\n",
        "dataset = load_dataset(\"winogrande\", 'winogrande_debiased')\n",
        "#dataset = load_dataset(\"winogrande\", 'winogrande_l')\n",
        "\n",
        "# dataset is dict with keys ['train', 'test', 'validation']\n",
        "# Each with an enumerable of \n",
        "\"\"\"\n",
        "{'answer': '2',\n",
        " 'option1': 'Kyle',\n",
        " 'option2': 'Logan',\n",
        " 'sentence': \"Kyle doesn't wear leg warmers to bed, while Logan almost always does. _ is more likely to live in a colder climate.\"}\n",
        "\n",
        "\"\"\"\n",
        "# Use Validation instead of Test because Test lacks labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyvVPUg5nij4"
      },
      "outputs": [],
      "source": [
        "# Textizer\n",
        "\"\"\"\n",
        "    Each sentence was split on \"_\" placeholder symbol.\n",
        "    Each option was concatenated with the second part of the split, thus transforming each example into two text segment pairs.\n",
        "    Text segment pairs corresponding to correct and incorrect options were marked with True and False labels accordingly.\n",
        "    Text segment pairs were shuffled thereafter.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "def prepare_data(dataset):\n",
        "\n",
        "  # internal function\n",
        "  def prep_ds(dataset):\n",
        "    sentences, answers, o1, o2 = [], [], [], []\n",
        "    for p in dataset:\n",
        "      s1 = p['option1'].join(p['sentence'].split('_'))\n",
        "      s2 = p['option2'].join(p['sentence'].split('_'))\n",
        "      a1 = int(p['answer'] == '1')\n",
        "      a2 = int(p['answer'] == '2')\n",
        "\n",
        "      \n",
        "      sentences.append(s1)\n",
        "      answers.append(a1)\n",
        "      sentences.append(s2)\n",
        "      answers.append(a2)\n",
        "      o1.append(p['option1'])\n",
        "      o2.append(p['option2'])\n",
        "      o1.append(p['option1'])\n",
        "      o2.append(p['option2'])\n",
        "\n",
        "    return {'sentence':sentences, 'labels':answers, 'option1':o1, 'option2':o2}\n",
        "    # end internal function\n",
        "\n",
        "  train = prep_ds(dataset[\"train\"])\n",
        "  test = prep_ds(dataset[\"validation\"])\n",
        "  trainds = Dataset.from_dict( train ).shuffle()\n",
        "  testds = Dataset.from_dict( test ).shuffle()\n",
        "\n",
        "  return {\"train\":trainds, \"test\":testds, \"name\":\"Standard Dataset\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def mask_datasets(dataset):\n",
        "\n",
        "  # internal method BEGIN\n",
        "  def mask_copy(dataset):\n",
        "    sentences = []\n",
        "    toprint = 10\n",
        "\n",
        "    for p in dataset:\n",
        "      if toprint > 0:\n",
        "        print(f\"[{p['option1']}], [{p['option2']}], [{p['sentence']}]\")\n",
        "\n",
        "      sentences.append(p['sentence'].replace(p['option1'], 'option1').replace(p['option2'], 'option2'))\n",
        "      \n",
        "      if toprint > 0:\n",
        "        print(sentences[-1])\n",
        "        toprint -= 1\n",
        "\n",
        "    build = {'sentence':sentences, 'labels':dataset['labels'], 'option1':dataset['option1'], 'option2':dataset['option2']}\n",
        "    return Dataset.from_dict(build) # DON'T SHUFFLE\n",
        "  #END\n",
        "  \n",
        "  return {\"train\":mask_copy(dataset['train']), \"test\":mask_copy(dataset['test']), \"name\":\"Masked Dataset\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "1eHIx_YjIVdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD8_o4yf9A8j"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\" \n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\")\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/roberta-large-winogrande\", model_max_length=64)\n",
        "\n",
        "def test_datasets(tokenizer, std_datasets, masked_datasets, model=False,):\n",
        "\n",
        "  print(\"Testing 1 2 3 ...\")\n",
        "  delete = False\n",
        "  if not model:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"DeepPavlov/roberta-large-winogrande\")\n",
        "    delete = True\n",
        "\n",
        "  elif isinstance(model, str):\n",
        "    delete = True\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    model = torch.load(model) # open(model, \"rb\"))\n",
        "\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "  try:\n",
        "    for ds in (std_datasets, masked_datasets):\n",
        "      print(\"Performing\", ds[\"name\"])\n",
        "      \n",
        "      #combinedtraintest = concatenate_datasets([ds['train'], ds['test']])\n",
        "      #encoded_train = combinedtraintest.map(lambda examples: tokenizer(examples['sentence'], padding='max_length'), batched=True) # , return_tensors='pt'\n",
        "      encoded_test = ds['test'].map(lambda examples: tokenizer(examples['sentence'], padding='max_length'), batched=True)\n",
        "\n",
        "      #encoded_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "      encoded_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "      #dataloader_train = torch.utils.data.DataLoader(encoded_train, batch_size=32)\n",
        "      dataloader_test = torch.utils.data.DataLoader(encoded_test, batch_size=32)\n",
        "\n",
        "      device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "      #model.train().to(device)\n",
        "      model.to(device)\n",
        "      #optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, batch in enumerate(tqdm(dataloader_test)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        #for oo, lab in zip(outputs.logits, batch['labels'] ):\n",
        "        #  print(oo.argmax().item(), lab.items())\n",
        "        correct += sum((int(x.argmax().item() == y.item()) for x, y in zip(outputs.logits, batch['labels'])))\n",
        "        total += len(batch['labels'])\n",
        "        \n",
        "        \n",
        "      print(\"Score\", correct / total, '/ 1.00')\n",
        "\n",
        "    if delete:\n",
        "      del model\n",
        "      print(\"Deleted model\")\n",
        "\n",
        "  except Exception as e:\n",
        "    del model\n",
        "    print(e, e.__str__)\n",
        "    print(\"Deleted model\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctmNv75-wmGH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#dicts of {'train':_, 'test':_}\n",
        "std_datasets = prepare_data(dataset)\n",
        "\n",
        "masked_datasets = mask_datasets(std_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWCsnqnlRxye"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model(trainingset, compareset, tokenizer, model=False, copy=False):\n",
        "  \n",
        "  if copy: # ie, if copy and model\n",
        "    print('copy')\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "    model = torch.load(model) # open(model, \"rb\"))\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "    #model_copy = type(model)() # get a new instance\n",
        "    #model_copy.load_state_dict(model.state_dict()) # copy weights and stuff\n",
        "    #model = model_copy\n",
        "    print('finished?')\n",
        "  elif model and isinstance(model, str): # ie if str(model) AND NOT copy:\n",
        "    # download new model of name\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model)\n",
        "\n",
        "  try:\n",
        "    encoded_train = trainingset['train'].map(lambda examples: tokenizer(examples['sentence'], padding='max_length'), batched=True) # , return_tensors='pt'\n",
        "    encoded_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "    dataloader_train = torch.utils.data.DataLoader(encoded_train, batch_size=32)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
        "    model.train().to(device)\n",
        "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
        "\n",
        "    for epoch in range(1):\n",
        "      print(\"Epoch\", epoch)\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, batch in enumerate(tqdm(dataloader_train)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        #for oo, lab in zip(outputs.logits, batch['labels'] ):\n",
        "        #  print(oo.argmax().item(), lab.items())\n",
        "        correct += sum((int(x.argmax().item() == y.item()) for x, y in zip(outputs.logits, batch['labels'])))\n",
        "        total += len(batch['labels'])\n",
        "        \n",
        "      print(\"Score\", correct / total, '/ 1.00')\n",
        "      test_datasets(tokenizer, trainingset, compareset, model)\n",
        "      model.train().to(device)\n",
        "  except Exception as e:\n",
        "    del model\n",
        "    print(e, e.__str__)\n",
        "    print(\"deleted model\")\n",
        "  if copy:\n",
        "    del model\n",
        "  else:\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJJenvgKxstY"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def mask_copy_1(dataset, unk):\n",
        "  sentences = []\n",
        "  toprint = 5\n",
        "\n",
        "  for p in dataset:\n",
        "    # This is annoying because option1 can be substrings of other words, usually option2. They can also have uppercase letters. \n",
        "    # If one is a substring, then I will cover up the larger word with a temporary mask to not confuse anything else.\n",
        "    sentence = p['sentence']\n",
        "    option1, option2 = re.compile(p['option1'], re.IGNORECASE), re.compile(p['option2'], re.IGNORECASE)\n",
        "    maskedoption1, maskedoption2 = \"OPTION_ONE\", \"OPTION_TWO\"\n",
        "    first_search, second_search, first_mask, second_mask = None, None, None, None\n",
        "\n",
        "    # \"table\" in \"tablecloth\" --> cover bigger one\n",
        "    if len(p['option1']) > len(p['option2']):\n",
        "      # cover option1 first\n",
        "      first_search, second_search = option1, option2\n",
        "      first_mask, second_mask = maskedoption1, maskedoption2\n",
        "    else:\n",
        "      first_search, second_search = option2, option1\n",
        "      first_mask, second_mask = maskedoption2, maskedoption1\n",
        "    \n",
        "    sentence = first_search.sub(first_mask, sentence) #Mask the longer word with OPTION_ mask\n",
        "    sentence = second_search.sub(second_mask, sentence) #then the shorter one\n",
        "\n",
        "    # IT gets kinda confusing which word now to <IGNORE> because it's language and some words appear more than two, more than three, times. \n",
        "    # I think the smartest approach is to assume the final word used is the question word and mask that one. \n",
        "\n",
        "    # Find final word used\n",
        "    # maskedoption1 is the final word\n",
        "    if sentence.rfind(maskedoption1) > sentence.rfind(maskedoption2):\n",
        "      # IGNORE final word\n",
        "      # Convert other word back to original\n",
        "      sentence = sentence.replace(maskedoption1, unk)\n",
        "      sentence = sentence.replace(maskedoption2, p['option2'])\n",
        "    else:\n",
        "      sentence = sentence.replace(maskedoption2, unk)\n",
        "      sentence = sentence.replace(maskedoption1, p['option2'])\n",
        "\n",
        "\n",
        "    if toprint > 0:\n",
        "      print(f\"[{p['option1']}], [{p['option2']}], [{p['sentence']}]\")\n",
        "\n",
        "    sentences.append(sentence)\n",
        "    \n",
        "    if toprint > 0:\n",
        "      print(sentences[-1])\n",
        "      toprint -= 1\n",
        "\n",
        "  build = {'sentence':sentences, 'labels':dataset['labels'], 'option1':dataset['option1'], 'option2':dataset['option2']}\n",
        "  return Dataset.from_dict(build) # DON'T SHUFFLE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mask_datasets_1(dataset, tokenizer):\n",
        "  unk = tokenizer.unk_token\n",
        "  return {\"train\":mask_copy_1(dataset['train'], unk), \"test\":mask_copy_1(dataset['test'], unk), \"name\":\"Double <Unk> Masked Dataset\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUj9r6mk4lvB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# This masked <unk> tokens on the option which is NOT involved in the question. \n",
        "# If the option involved in the question is wrong, it will need to identify the <unk> token as having importance.\n",
        "def mask_copy_2(dataset, unk):\n",
        "  sentences = []\n",
        "  toprint = 5\n",
        "\n",
        "  for p in dataset:\n",
        "    # This is annoying because option1 can be substrings of other words, usually option2. They can also have uppercase letters. \n",
        "    # If one is a substring, then I will cover up the larger word with a temporary mask to not confuse anything else.\n",
        "    sentence = p['sentence']\n",
        "    option1, option2 = re.compile(p['option1'], re.IGNORECASE), re.compile(p['option2'], re.IGNORECASE)\n",
        "    maskedoption1, maskedoption2 = \"OPTION_ONE\", \"OPTION_TWO\"\n",
        "    first_search, second_search, first_mask, second_mask = None, None, None, None\n",
        "\n",
        "    # \"table\" in \"tablecloth\" --> cover bigger one\n",
        "    if len(p['option1']) > len(p['option2']):\n",
        "      # cover option1 first\n",
        "      first_search, second_search = option1, option2\n",
        "      first_mask, second_mask = maskedoption1, maskedoption2\n",
        "    else:\n",
        "      first_search, second_search = option2, option1\n",
        "      first_mask, second_mask = maskedoption2, maskedoption1\n",
        "    \n",
        "    sentence = first_search.sub(first_mask, sentence) #Mask the longer word with OPTION_ mask\n",
        "    sentence = second_search.sub(second_mask, sentence) #then the shorter one\n",
        "\n",
        "    # IT gets kinda confusing which word now to <IGNORE> because it's language and some words appear more than two, more than three, times. \n",
        "    # I think the smartest approach is to assume the final word used is the question word and mask that one. \n",
        "\n",
        "    # Find final word used\n",
        "    # maskedoption1 is NOT the final word\n",
        "    if sentence.rfind(maskedoption1) < sentence.rfind(maskedoption2):\n",
        "      # IGNORE final word\n",
        "      # Convert other word back to original\n",
        "      sentence = sentence.replace(maskedoption1, unk)\n",
        "      sentence = sentence.replace(maskedoption2, p['option2'])\n",
        "    else:\n",
        "      sentence = sentence.replace(maskedoption2, unk)\n",
        "      sentence = sentence.replace(maskedoption1, p['option2'])\n",
        "\n",
        "\n",
        "    if toprint > 0:\n",
        "      print(f\"[{p['option1']}], [{p['option2']}], [{p['sentence']}]\")\n",
        "\n",
        "    sentences.append(sentence)\n",
        "    \n",
        "    if toprint > 0:\n",
        "      print(sentences[-1])\n",
        "      toprint -= 1\n",
        "\n",
        "  build = {'sentence':sentences, 'labels':dataset['labels'], 'option1':dataset['option1'], 'option2':dataset['option2']}\n",
        "  return Dataset.from_dict(build) # DON'T SHUFFLE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mask_datasets_2(dataset, tokenizer):\n",
        "  unk = tokenizer.unk_token\n",
        "  return {\"train\":mask_copy_2(dataset['train'], unk), \"test\":mask_copy_2(dataset['test'], unk), \"name\":\"Single <Unk> Masked Dataset\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stupid_tries = [\n",
        "  (\"dog\", \"doggy\"),\n",
        "  (\"red\", \"blue\"),\n",
        "  (\"flavor\", \"flavour\"),\n",
        "  ('A', 'B'),\n",
        "  ('X', 'Y'),\n",
        "  ('1', '2'),\n",
        "  ('first', 'second'),\n",
        "  ('alpha', 'beta'),\n",
        "  ('#', '@'),\n",
        "  ('primero', 'secundo'), # yes its true, I dont speak spanish. Having it spelled wrong just makes the model's task that much more difficult ;)\n",
        "  ('Alice', 'Bob'),\n",
        "  ('_', '__'),\n",
        "  ('mask1', 'mask2'),\n",
        "  ('thing1', 'thing2'),\n",
        "  ('mask_a', 'mask_b'),\n",
        "  (\"thing_a\", \"thing_b\")\n",
        "]\n"
      ],
      "metadata": {
        "id": "uO3kaYKyosEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# This masked <unk> tokens on the option which is NOT involved in the question. \n",
        "# If the option involved in the question is wrong, it will need to identify the <unk> token as having importance.\n",
        "def stupid_masking(dataset, mask1, mask2):\n",
        "  sentences = []\n",
        "  toprint = 1\n",
        "\n",
        "  for p in dataset:\n",
        "    # This is annoying because option1 can be substrings of other words, usually option2. They can also have uppercase letters. \n",
        "    # If one is a substring, then I will cover up the larger word with a temporary mask to not confuse anything else.\n",
        "    sentence = p['sentence']\n",
        "    option1, option2 = re.compile(p['option1'], re.IGNORECASE), re.compile(p['option2'], re.IGNORECASE)\n",
        "    maskedoption1, maskedoption2 = \"OPTION_ONE\", \"OPTION_TWO\"\n",
        "    first_search, second_search, first_mask, second_mask = None, None, None, None\n",
        "\n",
        "    # \"table\" in \"tablecloth\" --> cover bigger one\n",
        "    if len(p['option1']) > len(p['option2']):\n",
        "      # cover option1 first\n",
        "      first_search, second_search = option1, option2\n",
        "      first_mask, second_mask = maskedoption1, maskedoption2\n",
        "    else:\n",
        "      first_search, second_search = option2, option1\n",
        "      first_mask, second_mask = maskedoption2, maskedoption1\n",
        "    \n",
        "    sentence = first_search.sub(first_mask, sentence) #Mask the longer word with OPTION_ mask\n",
        "    sentence = second_search.sub(second_mask, sentence) #then the shorter one\n",
        "\n",
        "    sentence = sentence.replace(maskedoption1, mask1)\n",
        "    sentence = sentence.replace(maskedoption2, mask2)\n",
        "\n",
        "\n",
        "    if toprint > 0:\n",
        "      print(f\"[{p['option1']}], [{p['option2']}], [{p['sentence']}]\")\n",
        "\n",
        "    sentences.append(sentence)\n",
        "    \n",
        "    if toprint > 0:\n",
        "      print(sentences[-1])\n",
        "      toprint -= 1\n",
        "\n",
        "  build = {'sentence':sentences, 'labels':dataset['labels'], 'option1':dataset['option1'], 'option2':dataset['option2']}\n",
        "  return Dataset.from_dict(build) # DON'T SHUFFLE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def stupid_datasets(dataset, tokenizer, masks):\n",
        "  mask1, mask2 = masks\n",
        "  return {\"train\":stupid_masking(dataset['train'], mask1, mask2), \"test\":stupid_masking(dataset['test'], mask1, mask2), \"name\":f\"({mask1}, {mask2}) Masked Dataset\"}"
      ],
      "metadata": {
        "id": "zWfGHxA7Z6td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This model will become the base model for everything we build upon, \n",
        "# so we will save it to disk to load it fresh for each experiment. \n",
        "debiased_tuned_model = train_model(std_datasets, masked_datasets, tokenizer, model=\"DeepPavlov/roberta-large-winogrande\", copy=False)\n",
        "torch.save(debiased_tuned_model, f=\"debiased_model\")\n",
        "debiased_tuned_model = None\n",
        "\n",
        "test_datasets(tokenizer, std_datasets, masked_datasets)\n",
        "# How does it do on tra\n",
        "train_model(masked_datasets, std_datasets, tokenizer, model=\"debiased_model\", copy = True)\n",
        "unk_datasets = mask_datasets_1(std_datasets, tokenizer)\n",
        "test_datasets(tokenizer, std_datasets, unk_datasets, debiased_tuned_model)\n"
      ],
      "metadata": {
        "id": "w6Wcrmu4oQXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6ovn9Dhm7CY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCVu14WG41mK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e1GLEgz5ALP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql2g3gAdsl3g"
      },
      "outputs": [],
      "source": [
        "train_model(unk_datasets, std_datasets, tokenizer, model=\"debiased_model\", copy = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICjYC4yW5Mqn"
      },
      "outputs": [],
      "source": [
        "unk_dataset_2 = mask_datasets_2(std_datasets, tokenizer)\n",
        "\n",
        "test_datasets(tokenizer, std_datasets, unk_dataset_2, debiased_tuned_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(unk_dataset_2, std_datasets, tokenizer, model=\"debiased_model\", copy = True)"
      ],
      "metadata": {
        "id": "HbAnb9GFWC1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for masks in stupid_tries[-2:]:\n",
        "  stupid_ds = stupid_datasets(std_datasets, tokenizer, masks)\n",
        "  print(\"TESTING:\")\n",
        "  test_datasets(tokenizer, std_datasets, stupid_ds, model=\"debiased_model\")\n",
        "  print(\"POST TRAINING:\")\n",
        "  train_model(stupid_ds, std_datasets, tokenizer, model=\"debiased_model\", copy = True)\n"
      ],
      "metadata": {
        "id": "OiuQCDsead3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "\n",
        "| Masking Scheme | Accuracy (before training) | Accuracy (after training on silly set) |\n",
        "|:-------:|:------------------:|:----------------:|\n",
        "|Standard set| 75% | 75% |\n",
        "|(Alice, Bob)| 73% | 73% |\n",
        "|(primero, secundo)| 72% | 75% |\n",
        "| (X, Y) | 72% | 74% |\n",
        "| (A, B) | 72% | 73% |\n",
        "| (1, 2) | 71% | 74% |\n",
        "|(red, blue) | 71% | 73% |\n",
        "|(#, @)| 71% | 73% |\n",
        "|(alpha, beta)| 71% | 73% |\n",
        "|(mask_a, mask_b) | 70% | 75% | \n",
        "|(thing_a, thing_b) | 70% | 73% |\n",
        "|(first, second)| 69% | 73% |\n",
        "|(\\_, \\_\\_)| 67% | 73% |\n",
        "|(dog, doggy)| 65% | 73% | \n",
        "|(flavor, flavour)| 53% | 74% |\n",
        "\n",
        "\n",
        "\n",
        "| Masking Scheme | Accuracy (before training) | Accuracy (after training on \\<unk\\> masked set) |\n",
        "|:-------:|:------------------:|:----------------:|\n",
        "|\\<unk\\> as subj| 65% | 73% |\n",
        "|\\<unk\\> as obj| 68% | 73% |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3k32Vfxq-YLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qNws0djclgtz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Extension of Summerwinograndeattempt to more models",
      "provenance": [],
      "authorship_tag": "ABX9TyOeppyBfisKiuStzr310NqS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}